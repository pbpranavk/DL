{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsGd8jjJApus"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data, setting up the model and plotting graphs with first 20 items and the rest as validation set"
      ],
      "metadata": {
        "id": "ntZir8-iYA0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1ulUWDvDrA1"
      },
      "outputs": [],
      "source": [
        "mnist_dataset = datasets.MNIST(\n",
        "    root = \"datasets\",\n",
        "    train = True,\n",
        "    download=True,\n",
        "    transform = ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = []\n",
        "validation_dataset = []\n",
        "\n",
        "for j, item in enumerate(mnist_dataset):\n",
        "        if j < 20:\n",
        "          train_dataset.append(item)\n",
        "        else:\n",
        "          validation_dataset.append(item)"
      ],
      "metadata": {
        "id": "BXiaHOoCOcvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhqC9NEDO-Sf",
        "outputId": "dc5ca756-e994-454e-a722-a45ce5b158ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59980"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_B-Wm5tFZAs"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=20,\n",
        "        drop_last=False,\n",
        "        shuffle=True,\n",
        "        num_workers=0)\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "        dataset=validation_dataset,\n",
        "        batch_size=20,\n",
        "        shuffle=False,\n",
        "        num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XneVsyhxEVrs"
      },
      "outputs": [],
      "source": [
        "class MNISTClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_features, num_hidden1, num_hidden2, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(num_features, num_hidden1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(num_hidden1, num_hidden2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(num_hidden2, num_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "model = MNISTClassifier(num_features=28*28,\n",
        "            num_hidden1=50,\n",
        "            num_hidden2=20,\n",
        "            num_classes=10)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, data_loader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n"
      ],
      "metadata": {
        "id": "k4Z7wGsMqN-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9rgpD9REXh7",
        "outputId": "04b3d3f0-5679-425e-f6bd-27e13bb2bc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 : loss - 2.273500919342041\n",
            "Epoch 2 : loss - 2.2662720680236816\n",
            "Epoch 3 : loss - 2.2597827911376953\n",
            "Epoch 4 : loss - 2.2535927295684814\n",
            "Epoch 5 : loss - 2.247537612915039\n",
            "Epoch 6 : loss - 2.241497278213501\n",
            "Epoch 7 : loss - 2.2353029251098633\n",
            "Epoch 8 : loss - 2.229020118713379\n",
            "Epoch 9 : loss - 2.22263765335083\n",
            "Epoch 10 : loss - 2.216282367706299\n",
            "Epoch 11 : loss - 2.2096166610717773\n",
            "Epoch 12 : loss - 2.202549695968628\n",
            "Epoch 13 : loss - 2.1953721046447754\n",
            "Epoch 14 : loss - 2.1881895065307617\n",
            "Epoch 15 : loss - 2.180872917175293\n",
            "Epoch 16 : loss - 2.1733288764953613\n",
            "Epoch 17 : loss - 2.1654722690582275\n",
            "Epoch 18 : loss - 2.1572177410125732\n",
            "Epoch 19 : loss - 2.1487886905670166\n",
            "Epoch 20 : loss - 2.1400437355041504\n",
            "Epoch 21 : loss - 2.1311264038085938\n",
            "Epoch 22 : loss - 2.122016429901123\n",
            "Epoch 23 : loss - 2.112189769744873\n",
            "Epoch 24 : loss - 2.1021981239318848\n",
            "Epoch 25 : loss - 2.0918984413146973\n",
            "Epoch 26 : loss - 2.081373691558838\n",
            "Epoch 27 : loss - 2.070620059967041\n",
            "Epoch 28 : loss - 2.05942964553833\n",
            "Epoch 29 : loss - 2.0478386878967285\n",
            "Epoch 30 : loss - 2.035766839981079\n",
            "Epoch 31 : loss - 2.0232434272766113\n",
            "Epoch 32 : loss - 2.010471820831299\n",
            "Epoch 33 : loss - 1.9973983764648438\n",
            "Epoch 34 : loss - 1.9841161966323853\n",
            "Epoch 35 : loss - 1.9709562063217163\n",
            "Epoch 36 : loss - 1.957146406173706\n",
            "Epoch 37 : loss - 1.942562460899353\n",
            "Epoch 38 : loss - 1.9278377294540405\n",
            "Epoch 39 : loss - 1.913206696510315\n",
            "Epoch 40 : loss - 1.8985824584960938\n",
            "Epoch 41 : loss - 1.883587121963501\n",
            "Epoch 42 : loss - 1.8689050674438477\n",
            "Epoch 43 : loss - 1.8539537191390991\n",
            "Epoch 44 : loss - 1.8392305374145508\n",
            "Epoch 45 : loss - 1.8243401050567627\n",
            "Epoch 46 : loss - 1.8092563152313232\n",
            "Epoch 47 : loss - 1.7941429615020752\n",
            "Epoch 48 : loss - 1.7798573970794678\n",
            "Epoch 49 : loss - 1.7652397155761719\n",
            "Epoch 50 : loss - 1.7510461807250977\n",
            "Epoch 51 : loss - 1.7361923456192017\n",
            "Epoch 52 : loss - 1.7216594219207764\n",
            "Epoch 53 : loss - 1.706788420677185\n",
            "Epoch 54 : loss - 1.6923964023590088\n",
            "Epoch 55 : loss - 1.677997350692749\n",
            "Epoch 56 : loss - 1.6632602214813232\n",
            "Epoch 57 : loss - 1.6490545272827148\n",
            "Epoch 58 : loss - 1.6345382928848267\n",
            "Epoch 59 : loss - 1.6198556423187256\n",
            "Epoch 60 : loss - 1.6053636074066162\n",
            "Epoch 61 : loss - 1.59088134765625\n",
            "Epoch 62 : loss - 1.5760581493377686\n",
            "Epoch 63 : loss - 1.561292052268982\n",
            "Epoch 64 : loss - 1.5466268062591553\n",
            "Epoch 65 : loss - 1.5321145057678223\n",
            "Epoch 66 : loss - 1.5172773599624634\n",
            "Epoch 67 : loss - 1.5023319721221924\n",
            "Epoch 68 : loss - 1.4875996112823486\n",
            "Epoch 69 : loss - 1.4728482961654663\n",
            "Epoch 70 : loss - 1.4578466415405273\n",
            "Epoch 71 : loss - 1.4429570436477661\n",
            "Epoch 72 : loss - 1.4280390739440918\n",
            "Epoch 73 : loss - 1.4131977558135986\n",
            "Epoch 74 : loss - 1.3983222246170044\n",
            "Epoch 75 : loss - 1.3840020895004272\n",
            "Epoch 76 : loss - 1.3687928915023804\n",
            "Epoch 77 : loss - 1.3540635108947754\n",
            "Epoch 78 : loss - 1.338850736618042\n",
            "Epoch 79 : loss - 1.3242148160934448\n",
            "Epoch 80 : loss - 1.3081347942352295\n",
            "Epoch 81 : loss - 1.2929490804672241\n",
            "Epoch 82 : loss - 1.2777180671691895\n",
            "Epoch 83 : loss - 1.2628097534179688\n",
            "Epoch 84 : loss - 1.2465089559555054\n",
            "Epoch 85 : loss - 1.2307343482971191\n",
            "Epoch 86 : loss - 1.2151985168457031\n",
            "Epoch 87 : loss - 1.1998472213745117\n",
            "Epoch 88 : loss - 1.1839118003845215\n",
            "Epoch 89 : loss - 1.1687278747558594\n",
            "Epoch 90 : loss - 1.1523158550262451\n",
            "Epoch 91 : loss - 1.1370224952697754\n",
            "Epoch 92 : loss - 1.1201847791671753\n",
            "Epoch 93 : loss - 1.1039364337921143\n",
            "Epoch 94 : loss - 1.0880916118621826\n",
            "Epoch 95 : loss - 1.0717623233795166\n",
            "Epoch 96 : loss - 1.0558865070343018\n",
            "Epoch 97 : loss - 1.0396511554718018\n",
            "Epoch 98 : loss - 1.0239017009735107\n",
            "Epoch 99 : loss - 1.0088902711868286\n",
            "Epoch 100 : loss - 0.9925673604011536\n",
            "Epoch 101 : loss - 0.976469874382019\n",
            "Epoch 102 : loss - 0.95994633436203\n",
            "Epoch 103 : loss - 0.9441773295402527\n",
            "Epoch 104 : loss - 0.928960919380188\n",
            "Epoch 105 : loss - 0.9140558242797852\n",
            "Epoch 106 : loss - 0.8967398405075073\n",
            "Epoch 107 : loss - 0.8804380297660828\n",
            "Epoch 108 : loss - 0.8650752902030945\n",
            "Epoch 109 : loss - 0.850745677947998\n",
            "Epoch 110 : loss - 0.8342645764350891\n",
            "Epoch 111 : loss - 0.8186185956001282\n",
            "Epoch 112 : loss - 0.8035866022109985\n",
            "Epoch 113 : loss - 0.7884201407432556\n",
            "Epoch 114 : loss - 0.772715151309967\n",
            "Epoch 115 : loss - 0.7581993341445923\n",
            "Epoch 116 : loss - 0.7435880303382874\n",
            "Epoch 117 : loss - 0.7286035418510437\n",
            "Epoch 118 : loss - 0.714399516582489\n",
            "Epoch 119 : loss - 0.6996414661407471\n",
            "Epoch 120 : loss - 0.6853412389755249\n",
            "Epoch 121 : loss - 0.6714490056037903\n",
            "Epoch 122 : loss - 0.6578158736228943\n",
            "Epoch 123 : loss - 0.6438537836074829\n",
            "Epoch 124 : loss - 0.6303890347480774\n",
            "Epoch 125 : loss - 0.6175909638404846\n",
            "Epoch 126 : loss - 0.6046721339225769\n",
            "Epoch 127 : loss - 0.5916340947151184\n",
            "Epoch 128 : loss - 0.578413188457489\n",
            "Epoch 129 : loss - 0.5660291314125061\n",
            "Epoch 130 : loss - 0.5543447136878967\n",
            "Epoch 131 : loss - 0.5425086617469788\n",
            "Epoch 132 : loss - 0.5302531123161316\n",
            "Epoch 133 : loss - 0.5183135867118835\n",
            "Epoch 134 : loss - 0.5076232552528381\n",
            "Epoch 135 : loss - 0.4970130920410156\n",
            "Epoch 136 : loss - 0.4853665828704834\n",
            "Epoch 137 : loss - 0.4742567539215088\n",
            "Epoch 138 : loss - 0.46347904205322266\n",
            "Epoch 139 : loss - 0.45356035232543945\n",
            "Epoch 140 : loss - 0.4439786970615387\n",
            "Epoch 141 : loss - 0.43337297439575195\n",
            "Epoch 142 : loss - 0.4234592318534851\n",
            "Epoch 143 : loss - 0.4142647683620453\n",
            "Epoch 144 : loss - 0.40475624799728394\n",
            "Epoch 145 : loss - 0.3952324688434601\n",
            "Epoch 146 : loss - 0.38655945658683777\n",
            "Epoch 147 : loss - 0.3775887191295624\n",
            "Epoch 148 : loss - 0.3687126338481903\n",
            "Epoch 149 : loss - 0.3606404662132263\n",
            "Epoch 150 : loss - 0.3522804379463196\n",
            "Epoch 151 : loss - 0.3443675637245178\n",
            "Epoch 152 : loss - 0.3362904191017151\n",
            "Epoch 153 : loss - 0.328213632106781\n",
            "Epoch 154 : loss - 0.32068151235580444\n",
            "Epoch 155 : loss - 0.3132289946079254\n",
            "Epoch 156 : loss - 0.3060309886932373\n",
            "Epoch 157 : loss - 0.2986438572406769\n",
            "Epoch 158 : loss - 0.292184442281723\n",
            "Epoch 159 : loss - 0.2854054868221283\n",
            "Epoch 160 : loss - 0.27832573652267456\n",
            "Epoch 161 : loss - 0.27160462737083435\n",
            "Epoch 162 : loss - 0.26557523012161255\n",
            "Epoch 163 : loss - 0.25921064615249634\n",
            "Epoch 164 : loss - 0.25315389037132263\n",
            "Epoch 165 : loss - 0.247005894780159\n",
            "Epoch 166 : loss - 0.24115367233753204\n",
            "Epoch 167 : loss - 0.23551997542381287\n",
            "Epoch 168 : loss - 0.23001711070537567\n",
            "Epoch 169 : loss - 0.2243201732635498\n",
            "Epoch 170 : loss - 0.21902242302894592\n",
            "Epoch 171 : loss - 0.21404770016670227\n",
            "Epoch 172 : loss - 0.20935165882110596\n",
            "Epoch 173 : loss - 0.20402279496192932\n",
            "Epoch 174 : loss - 0.19909550249576569\n",
            "Epoch 175 : loss - 0.1945892870426178\n",
            "Epoch 176 : loss - 0.1901787370443344\n",
            "Epoch 177 : loss - 0.18561136722564697\n",
            "Epoch 178 : loss - 0.18135926127433777\n",
            "Epoch 179 : loss - 0.1771482527256012\n",
            "Epoch 180 : loss - 0.17308267951011658\n",
            "Epoch 181 : loss - 0.16917406022548676\n",
            "Epoch 182 : loss - 0.1653098315000534\n",
            "Epoch 183 : loss - 0.1614547073841095\n",
            "Epoch 184 : loss - 0.1580028533935547\n",
            "Epoch 185 : loss - 0.1541222780942917\n",
            "Epoch 186 : loss - 0.15073390305042267\n",
            "Epoch 187 : loss - 0.1473437398672104\n",
            "Epoch 188 : loss - 0.14416192471981049\n",
            "Epoch 189 : loss - 0.14098858833312988\n",
            "Epoch 190 : loss - 0.1378701776266098\n",
            "Epoch 191 : loss - 0.13494154810905457\n",
            "Epoch 192 : loss - 0.13201026618480682\n",
            "Epoch 193 : loss - 0.12917384505271912\n",
            "Epoch 194 : loss - 0.1264086663722992\n",
            "Epoch 195 : loss - 0.12378980964422226\n",
            "Epoch 196 : loss - 0.121188685297966\n",
            "Epoch 197 : loss - 0.11875877529382706\n",
            "Epoch 198 : loss - 0.11622896045446396\n",
            "Epoch 199 : loss - 0.11401591449975967\n",
            "Epoch 200 : loss - 0.11156954616308212\n"
          ]
        }
      ],
      "source": [
        "train_acc_list, valid_acc_list = [], []\n",
        "\n",
        "for epoch in range(200):\n",
        "\n",
        "  for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "    logits = model(features)\n",
        "    loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch + 1} : loss - {loss}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_acc = compute_accuracy(model, train_loader)\n",
        "    valid_acc = compute_accuracy(model, valid_loader)\n",
        "    train_acc_list.append(train_acc.item())\n",
        "    valid_acc_list.append(valid_acc.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hu6ZaO4sqldO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJRJo-dyFyHe"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(train_acc_list, valid_acc_list):\n",
        "\n",
        "    num_epochs = len(train_acc_list)\n",
        "\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             train_acc_list, label='Training')\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             valid_acc_list, label='Validation')\n",
        "    # plt.plot(np.arange(1, num_epochs+1),\n",
        "    #          test_acc_list, label='Test')\n",
        "\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy(train_acc_list, valid_acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "WrJgJp1mun9S",
        "outputId": "17c9b74f-1ad9-4fb1-9434-d2eca5c36981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here we can see that the accuracies at the end of 200 epochs are 100% for training and almost 45% to 50% for validation set. We can see this a clear case of overfitting, the reason being there are only 20 items for training data and the model was not able to generalise thereby overfitting and memorising the training 20 samples."
      ],
      "metadata": {
        "id": "nbqpvMa2fDdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmenting the data and training the model and plotting the results"
      ],
      "metadata": {
        "id": "yhEkSrLYYPgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "augmented_train_data = []\n",
        "\n",
        "my_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "for i in range(100):\n",
        "    mnist_new = datasets.MNIST('data', train=True, download=True, transform=my_transform)\n",
        "    for j, item in enumerate(mnist_new):\n",
        "        if j >= 20:\n",
        "            break\n",
        "        augmented_train_data.append(item)\n",
        "\n",
        "len(augmented_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL7LCUZ2qjPR",
        "outputId": "81a72102-f2ee-48d5-d8d3-b5edabeef5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "        dataset=augmented_train_data,\n",
        "        batch_size=20,\n",
        "        drop_last=False,\n",
        "        shuffle=True,\n",
        "        num_workers=0)\n"
      ],
      "metadata": {
        "id": "zQHyVMo_u8eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_augmented = MNISTClassifier(num_features=28*28,\n",
        "            num_hidden1=50,\n",
        "            num_hidden2=20,\n",
        "            num_classes=10)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model_augmented.parameters(), lr=0.05)"
      ],
      "metadata": {
        "id": "-e3oBK4iTrG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_list, valid_acc_list = [], []\n",
        "\n",
        "for epoch in range(200):\n",
        "\n",
        "  for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "    logits = model_augmented(features)\n",
        "    loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch + 1} : loss - {loss}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    train_acc = compute_accuracy(model_augmented, train_loader)\n",
        "    valid_acc = compute_accuracy(model_augmented, valid_loader)\n",
        "    train_acc_list.append(train_acc.item())\n",
        "    valid_acc_list.append(valid_acc.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFQnbvR6u03D",
        "outputId": "6adcd3bb-6aa0-4d56-e316-e3c70f066003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 : loss - 1.4949709177017212\n",
            "Epoch 2 : loss - 0.5933522582054138\n",
            "Epoch 3 : loss - 0.17367130517959595\n",
            "Epoch 4 : loss - 0.07415150105953217\n",
            "Epoch 5 : loss - 0.025140877813100815\n",
            "Epoch 6 : loss - 0.028671782463788986\n",
            "Epoch 7 : loss - 0.017751967534422874\n",
            "Epoch 8 : loss - 0.013562297448515892\n",
            "Epoch 9 : loss - 0.006646392401307821\n",
            "Epoch 10 : loss - 0.007758378051221371\n",
            "Epoch 11 : loss - 0.005335135851055384\n",
            "Epoch 12 : loss - 0.003506205976009369\n",
            "Epoch 13 : loss - 0.0034095991868525743\n",
            "Epoch 14 : loss - 0.0029313373379409313\n",
            "Epoch 15 : loss - 0.002081753686070442\n",
            "Epoch 16 : loss - 0.002574005862697959\n",
            "Epoch 17 : loss - 0.00266580143943429\n",
            "Epoch 18 : loss - 0.0019809151999652386\n",
            "Epoch 19 : loss - 0.0022191740572452545\n",
            "Epoch 20 : loss - 0.0029121118132025003\n",
            "Epoch 21 : loss - 0.0019288432085886598\n",
            "Epoch 22 : loss - 0.0017912887269631028\n",
            "Epoch 23 : loss - 0.0009159217588603497\n",
            "Epoch 24 : loss - 0.0019340630387887359\n",
            "Epoch 25 : loss - 0.0011556936660781503\n",
            "Epoch 26 : loss - 0.001646043499931693\n",
            "Epoch 27 : loss - 0.001702532172203064\n",
            "Epoch 28 : loss - 0.001592966029420495\n",
            "Epoch 29 : loss - 0.00145477126352489\n",
            "Epoch 30 : loss - 0.000706104445271194\n",
            "Epoch 31 : loss - 0.0012413051445037127\n",
            "Epoch 32 : loss - 0.0008287357049994171\n",
            "Epoch 33 : loss - 0.00112997239921242\n",
            "Epoch 34 : loss - 0.0007323658210225403\n",
            "Epoch 35 : loss - 0.0008801334770396352\n",
            "Epoch 36 : loss - 0.0013989332364872098\n",
            "Epoch 37 : loss - 0.001021025120280683\n",
            "Epoch 38 : loss - 0.00071461230982095\n",
            "Epoch 39 : loss - 0.0003639651113189757\n",
            "Epoch 40 : loss - 0.0006471484084613621\n",
            "Epoch 41 : loss - 0.0005986822070553899\n",
            "Epoch 42 : loss - 0.000699736992828548\n",
            "Epoch 43 : loss - 0.0006289432640187442\n",
            "Epoch 44 : loss - 0.0007826498476788402\n",
            "Epoch 45 : loss - 0.0007130628218874335\n",
            "Epoch 46 : loss - 0.0007892389548942447\n",
            "Epoch 47 : loss - 0.00045548431808128953\n",
            "Epoch 48 : loss - 0.0006744224228896201\n",
            "Epoch 49 : loss - 0.0008304922957904637\n",
            "Epoch 50 : loss - 0.0005778653430752456\n",
            "Epoch 51 : loss - 0.0003641795483417809\n",
            "Epoch 52 : loss - 0.0003992714046034962\n",
            "Epoch 53 : loss - 0.00030028619221411645\n",
            "Epoch 54 : loss - 0.000560807588044554\n",
            "Epoch 55 : loss - 0.0004910117713734508\n",
            "Epoch 56 : loss - 0.0004290904907975346\n",
            "Epoch 57 : loss - 0.00046605890383943915\n",
            "Epoch 58 : loss - 0.0004399667086545378\n",
            "Epoch 59 : loss - 0.000418749958043918\n",
            "Epoch 60 : loss - 0.0003625661483965814\n",
            "Epoch 61 : loss - 0.0002458014932926744\n",
            "Epoch 62 : loss - 0.0005290706176310778\n",
            "Epoch 63 : loss - 0.0004858060274273157\n",
            "Epoch 64 : loss - 0.0003450840595178306\n",
            "Epoch 65 : loss - 0.0002993080415762961\n",
            "Epoch 66 : loss - 0.0004893773002550006\n",
            "Epoch 67 : loss - 0.00019316635734867305\n",
            "Epoch 68 : loss - 0.00028293702052906156\n",
            "Epoch 69 : loss - 0.0005848839646205306\n",
            "Epoch 70 : loss - 0.0002477327361702919\n",
            "Epoch 71 : loss - 0.0004531120357569307\n",
            "Epoch 72 : loss - 0.00028655497590079904\n",
            "Epoch 73 : loss - 0.0005606497870758176\n",
            "Epoch 74 : loss - 0.00021243006631266326\n",
            "Epoch 75 : loss - 0.0003734390193130821\n",
            "Epoch 76 : loss - 0.00042750959983095527\n",
            "Epoch 77 : loss - 0.0003037915739696473\n",
            "Epoch 78 : loss - 0.0003317426308058202\n",
            "Epoch 79 : loss - 0.0009806493762880564\n",
            "Epoch 80 : loss - 0.00022819200239609927\n",
            "Epoch 81 : loss - 0.00026686995988711715\n",
            "Epoch 82 : loss - 0.000242767040617764\n",
            "Epoch 83 : loss - 0.0002388445136602968\n",
            "Epoch 84 : loss - 0.00023055246856529266\n",
            "Epoch 85 : loss - 0.00026734924176707864\n",
            "Epoch 86 : loss - 0.0003658111672848463\n",
            "Epoch 87 : loss - 0.0002270239347126335\n",
            "Epoch 88 : loss - 0.00024172016128432006\n",
            "Epoch 89 : loss - 0.00016796542331576347\n",
            "Epoch 90 : loss - 0.00022848183289170265\n",
            "Epoch 91 : loss - 0.00022942255600355566\n",
            "Epoch 92 : loss - 0.00043210643343627453\n",
            "Epoch 93 : loss - 0.0002769010607153177\n",
            "Epoch 94 : loss - 0.00039702531648799777\n",
            "Epoch 95 : loss - 0.00025662750704213977\n",
            "Epoch 96 : loss - 0.00020265339117031544\n",
            "Epoch 97 : loss - 0.00019099769997410476\n",
            "Epoch 98 : loss - 0.0005159314023330808\n",
            "Epoch 99 : loss - 0.00014852687309030443\n",
            "Epoch 100 : loss - 0.00010831324470927939\n",
            "Epoch 101 : loss - 0.00019363270257599652\n",
            "Epoch 102 : loss - 0.00015398740652017295\n",
            "Epoch 103 : loss - 0.00021507397468667477\n",
            "Epoch 104 : loss - 0.00011879295198014006\n",
            "Epoch 105 : loss - 0.0001410724362358451\n",
            "Epoch 106 : loss - 0.0004007765091955662\n",
            "Epoch 107 : loss - 0.0002275024598930031\n",
            "Epoch 108 : loss - 0.0002683894126676023\n",
            "Epoch 109 : loss - 0.00040900736348703504\n",
            "Epoch 110 : loss - 0.000286637048702687\n",
            "Epoch 111 : loss - 0.0003073432599194348\n",
            "Epoch 112 : loss - 0.00016828750085551292\n",
            "Epoch 113 : loss - 0.00013768082135356963\n",
            "Epoch 114 : loss - 0.00018857928807847202\n",
            "Epoch 115 : loss - 0.00016474025323987007\n",
            "Epoch 116 : loss - 0.0003001021104864776\n",
            "Epoch 117 : loss - 0.00024238503829110414\n",
            "Epoch 118 : loss - 8.840301597956568e-05\n",
            "Epoch 119 : loss - 0.00017414669855497777\n",
            "Epoch 120 : loss - 0.00026175781385973096\n",
            "Epoch 121 : loss - 0.0002932530187536031\n",
            "Epoch 122 : loss - 0.00020996309467591345\n",
            "Epoch 123 : loss - 0.00022365304175764322\n",
            "Epoch 124 : loss - 0.00024816617951728404\n",
            "Epoch 125 : loss - 0.00018584675854071975\n",
            "Epoch 126 : loss - 0.0001329657679889351\n",
            "Epoch 127 : loss - 0.00024494589888490736\n",
            "Epoch 128 : loss - 0.00017440695955883712\n",
            "Epoch 129 : loss - 0.0001429644034942612\n",
            "Epoch 130 : loss - 0.00017417494382243603\n",
            "Epoch 131 : loss - 0.0002052031923085451\n",
            "Epoch 132 : loss - 0.00024411865160800517\n",
            "Epoch 133 : loss - 8.551559585612267e-05\n",
            "Epoch 134 : loss - 0.00014368080883286893\n",
            "Epoch 135 : loss - 0.00011896842624992132\n",
            "Epoch 136 : loss - 0.0001527771382825449\n",
            "Epoch 137 : loss - 0.00015149274258874357\n",
            "Epoch 138 : loss - 0.00015326065476983786\n",
            "Epoch 139 : loss - 0.00019820879970211536\n",
            "Epoch 140 : loss - 0.00012345350114628673\n",
            "Epoch 141 : loss - 0.00015695480396971107\n",
            "Epoch 142 : loss - 9.437688277103007e-05\n",
            "Epoch 143 : loss - 0.00017588280024938285\n",
            "Epoch 144 : loss - 0.00010691255010897294\n",
            "Epoch 145 : loss - 0.00031766953179612756\n",
            "Epoch 146 : loss - 0.0001531660236651078\n",
            "Epoch 147 : loss - 0.00012925430200994015\n",
            "Epoch 148 : loss - 0.00018002714205067605\n",
            "Epoch 149 : loss - 0.00016490225971210748\n",
            "Epoch 150 : loss - 0.00010077601473312825\n",
            "Epoch 151 : loss - 0.00010008351819124073\n",
            "Epoch 152 : loss - 0.00010003318311646581\n",
            "Epoch 153 : loss - 0.00015592209820169955\n",
            "Epoch 154 : loss - 0.0001061829534592107\n",
            "Epoch 155 : loss - 0.0001547029532957822\n",
            "Epoch 156 : loss - 0.00022734401863999665\n",
            "Epoch 157 : loss - 8.155610703397542e-05\n",
            "Epoch 158 : loss - 0.00017716403817757964\n",
            "Epoch 159 : loss - 0.0001360117457807064\n",
            "Epoch 160 : loss - 0.0001105018745874986\n",
            "Epoch 161 : loss - 0.0001025576057145372\n",
            "Epoch 162 : loss - 0.00014942190318834037\n",
            "Epoch 163 : loss - 9.973285341402516e-05\n",
            "Epoch 164 : loss - 0.00011259852908551693\n",
            "Epoch 165 : loss - 6.829465564806014e-05\n",
            "Epoch 166 : loss - 0.0003081505710724741\n",
            "Epoch 167 : loss - 9.691275772638619e-05\n",
            "Epoch 168 : loss - 0.0001531100569991395\n",
            "Epoch 169 : loss - 5.4654454288538545e-05\n",
            "Epoch 170 : loss - 0.0001829340762924403\n",
            "Epoch 171 : loss - 6.16035467828624e-05\n",
            "Epoch 172 : loss - 0.0002535647654440254\n",
            "Epoch 173 : loss - 0.00015061160956975073\n",
            "Epoch 174 : loss - 7.02746183378622e-05\n",
            "Epoch 175 : loss - 0.00016708756447769701\n",
            "Epoch 176 : loss - 5.6585133279440925e-05\n",
            "Epoch 177 : loss - 5.704434079234488e-05\n",
            "Epoch 178 : loss - 5.8319994423072785e-05\n",
            "Epoch 179 : loss - 0.00011326429375912994\n",
            "Epoch 180 : loss - 7.943230593809858e-05\n",
            "Epoch 181 : loss - 8.482746488880366e-05\n",
            "Epoch 182 : loss - 0.00011418241774663329\n",
            "Epoch 183 : loss - 0.00010943214874714613\n",
            "Epoch 184 : loss - 0.00010317769920220599\n",
            "Epoch 185 : loss - 4.6906861825846136e-05\n",
            "Epoch 186 : loss - 0.0001734198012854904\n",
            "Epoch 187 : loss - 0.00011031079338863492\n",
            "Epoch 188 : loss - 9.244775719707832e-05\n",
            "Epoch 189 : loss - 0.00010972793825203553\n",
            "Epoch 190 : loss - 0.00015520474698860198\n",
            "Epoch 191 : loss - 7.455128070432693e-05\n",
            "Epoch 192 : loss - 8.501976844854653e-05\n",
            "Epoch 193 : loss - 6.268850120250136e-05\n",
            "Epoch 194 : loss - 0.0002017999067902565\n",
            "Epoch 195 : loss - 0.00012955584679730237\n",
            "Epoch 196 : loss - 8.11499630799517e-05\n",
            "Epoch 197 : loss - 9.980153845390305e-05\n",
            "Epoch 198 : loss - 0.0001842406636569649\n",
            "Epoch 199 : loss - 0.00015157477173488587\n",
            "Epoch 200 : loss - 8.589467324782163e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy(train_acc_list, valid_acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "RaZUjORRu-aS",
        "outputId": "7af753e7-c2d5-4f8d-c356-e920ce04dc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Even in this, with the augmentation the training accuracy becomes 100% whereas the validation accuracy is almost 60%, a signmificant improvement from the previous case but it is still overfitting.\n",
        "\n",
        "## We can see that augmenting data and increasing the training set size has reduced overfitting and helped in generalising the model but the difference between training and validation accuracies is still large and the model is still overfitting."
      ],
      "metadata": {
        "id": "vOzJgSoAhKrS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TQQ9ee_v6ya"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}