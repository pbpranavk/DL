{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BAQ9bgGJvcPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Answer, Minibatch version for high-level implementation of Softmax Regression"
      ],
      "metadata": {
        "id": "_OpNWGZguQWN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h36dh5lgf5Ux"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./iris.data', index_col=None, header=None)\n",
        "df.columns = ['x1', 'x2', 'x3', 'x4', 'y']\n",
        "\n",
        "d = {'Iris-versicolor': 1,\n",
        "     'Iris-virginica': 2,\n",
        "     'Iris-setosa': 0,\n",
        "}\n",
        "\n",
        "df['y'] = df['y'].map(d)\n",
        "\n",
        "# Assign features and target\n",
        "\n",
        "X = torch.tensor(df[['x2', 'x4']].values, dtype=torch.float)\n",
        "y = torch.tensor(df['y'].values, dtype=torch.int)\n",
        "\n",
        "# Shuffling & train/test split\n",
        "\n",
        "torch.manual_seed(123)\n",
        "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
        "\n",
        "X, y = X[shuffle_idx], y[shuffle_idx]\n",
        "\n",
        "percent80 = int(shuffle_idx.size(0)*0.8)\n",
        "\n",
        "X_train, X_test = X[shuffle_idx[:percent80]], X[shuffle_idx[percent80:]]\n",
        "y_train, y_test = y[shuffle_idx[:percent80]], y[shuffle_idx[percent80:]]\n",
        "\n",
        "# Normalize (mean zero, unit variance)\n",
        "\n",
        "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
        "X_train = (X_train - mu) / sigma\n",
        "X_test = (X_test - mu) / sigma\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(7, 2.5))\n",
        "ax[0].scatter(X_train[y_train == 2, 0], X_train[y_train == 2, 1])\n",
        "ax[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], marker='v')\n",
        "ax[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], marker='s')\n",
        "ax[1].scatter(X_test[y_test == 2, 0], X_test[y_test == 2, 1])\n",
        "ax[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], marker='v')\n",
        "ax[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], marker='s')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "J9tEM0f1goaO",
        "outputId": "e1d42b95-8725-4c88-d4a5-547428dd5f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x180 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxRegression2(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(SoftmaxRegression2, self).__init__()\n",
        "        self.linear = torch.nn.Linear(num_features, num_classes)\n",
        "\n",
        "        self.linear.weight.detach().zero_()\n",
        "        self.linear.bias.detach().zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "\n",
        "    def predict_labels(self, x):\n",
        "        logits, probas = self.forward(x)\n",
        "        labels = torch.argmax(probas, dim=1)\n",
        "        return labels\n",
        "\n",
        "    def evaluate(self, x, y):\n",
        "        labels = self.predict_labels(x).float()\n",
        "        accuracy = torch.sum(labels.view(-1) == y.float()).item() / y.size(0)\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "model2 = SoftmaxRegression2(num_features=2, num_classes=3)\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "lzRFhnO-gvQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comp_accuracy(true_labels, pred_labels):\n",
        "    accuracy = torch.sum(true_labels.view(-1).float() ==\n",
        "                         pred_labels.float()).item() / true_labels.size(0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "epochs_cost = []\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    current_iteration = 0\n",
        "\n",
        "    print(f\"------Epoch {epoch + 1}-------\")\n",
        "\n",
        "    for iter in range(y_train.shape[0] // 25): # 25 batches for epoch\n",
        "      mini_x = X_train[current_iteration: current_iteration + 25]\n",
        "      mini_y = y_train[current_iteration: current_iteration + 25]\n",
        "      current_iteration += 25\n",
        "\n",
        "      #### Compute outputs ####\n",
        "      logits, probas = model2(mini_x)\n",
        "\n",
        "      #### Compute gradients ####\n",
        "      cost = F.cross_entropy(logits, mini_y.long())\n",
        "      optimizer.zero_grad()\n",
        "      cost.backward()\n",
        "\n",
        "      #### Update weights ####\n",
        "      optimizer.step()\n",
        "\n",
        "      #### Logging ####\n",
        "      logits, probas = model2(mini_x)\n",
        "      acc = comp_accuracy(mini_y, torch.argmax(probas, dim=1))\n",
        "      print('Mini batch: %d' % ((iter + 1 )* 25 ), end=\"\")\n",
        "      print(' | Train ACC: %.3f' % acc, end=\"\")\n",
        "      print(' | Cost: %.3f' % F.cross_entropy(logits, mini_y.long()))\n",
        "      epochs_cost.append(cost)\n",
        "\n",
        "\n",
        "print('\\nModel parameters:')\n",
        "print('  Weights: %s' % model2.linear.weight)\n",
        "print('  Bias: %s' % model2.linear.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eu-UjL7hDI9",
        "outputId": "d121ba5c-d19a-4738-cae5-34a151077b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------Epoch 1-------\n",
            "Mini batch: 25 | Train ACC: 0.800 | Cost: 1.057\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 1.002\n",
            "Mini batch: 75 | Train ACC: 0.880 | Cost: 0.959\n",
            "Mini batch: 100 | Train ACC: 0.840 | Cost: 0.946\n",
            "------Epoch 2-------\n",
            "Mini batch: 25 | Train ACC: 0.800 | Cost: 0.923\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 0.854\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.827\n",
            "Mini batch: 100 | Train ACC: 0.840 | Cost: 0.836\n",
            "------Epoch 3-------\n",
            "Mini batch: 25 | Train ACC: 0.800 | Cost: 0.823\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 0.751\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.732\n",
            "Mini batch: 100 | Train ACC: 0.840 | Cost: 0.757\n",
            "------Epoch 4-------\n",
            "Mini batch: 25 | Train ACC: 0.800 | Cost: 0.748\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 0.676\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.664\n",
            "Mini batch: 100 | Train ACC: 0.840 | Cost: 0.698\n",
            "------Epoch 5-------\n",
            "Mini batch: 25 | Train ACC: 0.800 | Cost: 0.690\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 0.621\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.613\n",
            "Mini batch: 100 | Train ACC: 0.840 | Cost: 0.651\n",
            "------Epoch 6-------\n",
            "Mini batch: 25 | Train ACC: 0.800 | Cost: 0.644\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 0.578\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.573\n",
            "Mini batch: 100 | Train ACC: 0.840 | Cost: 0.615\n",
            "------Epoch 7-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.606\n",
            "Mini batch: 50 | Train ACC: 0.920 | Cost: 0.543\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.543\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.585\n",
            "------Epoch 8-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.575\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.515\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.518\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.560\n",
            "------Epoch 9-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.548\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.491\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.498\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.539\n",
            "------Epoch 10-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.526\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.471\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.481\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.521\n",
            "------Epoch 11-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.506\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.454\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.467\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.505\n",
            "------Epoch 12-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.489\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.439\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.454\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.492\n",
            "------Epoch 13-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.474\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.425\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.444\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.480\n",
            "------Epoch 14-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.461\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.413\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.435\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.469\n",
            "------Epoch 15-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.449\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.402\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.427\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.459\n",
            "------Epoch 16-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.438\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.393\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.420\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.450\n",
            "------Epoch 17-------\n",
            "Mini batch: 25 | Train ACC: 0.840 | Cost: 0.428\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.384\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.414\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.442\n",
            "------Epoch 18-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.419\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.376\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.408\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.435\n",
            "------Epoch 19-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.411\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.368\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.403\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.428\n",
            "------Epoch 20-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.403\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.362\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.398\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.422\n",
            "------Epoch 21-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.396\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.355\n",
            "Mini batch: 75 | Train ACC: 0.800 | Cost: 0.394\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.416\n",
            "------Epoch 22-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.390\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.349\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.389\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.410\n",
            "------Epoch 23-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.384\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.344\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.386\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.405\n",
            "------Epoch 24-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.378\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.339\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.382\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.401\n",
            "------Epoch 25-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.373\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.334\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.379\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.396\n",
            "------Epoch 26-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.368\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.329\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.376\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.392\n",
            "------Epoch 27-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.363\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.325\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.373\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.388\n",
            "------Epoch 28-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.358\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.321\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.370\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.384\n",
            "------Epoch 29-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.354\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.317\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.368\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.380\n",
            "------Epoch 30-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.350\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.313\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.365\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.377\n",
            "------Epoch 31-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.346\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.310\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.363\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.374\n",
            "------Epoch 32-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.342\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.306\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.360\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.370\n",
            "------Epoch 33-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.339\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.303\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.358\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.367\n",
            "------Epoch 34-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.335\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.300\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.356\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.364\n",
            "------Epoch 35-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.332\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.297\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.354\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.362\n",
            "------Epoch 36-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.329\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.294\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.352\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.359\n",
            "------Epoch 37-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.326\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.292\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.350\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.356\n",
            "------Epoch 38-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.323\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.289\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.348\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.354\n",
            "------Epoch 39-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.320\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.286\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.346\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.351\n",
            "------Epoch 40-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.318\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.284\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.345\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.349\n",
            "------Epoch 41-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.315\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.282\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.343\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.346\n",
            "------Epoch 42-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.313\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.279\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.341\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.344\n",
            "------Epoch 43-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.310\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.277\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.340\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.342\n",
            "------Epoch 44-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.308\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.275\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.338\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.340\n",
            "------Epoch 45-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.305\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.273\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.336\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.337\n",
            "------Epoch 46-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.303\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.271\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.335\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.335\n",
            "------Epoch 47-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.301\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.269\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.333\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.333\n",
            "------Epoch 48-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.299\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.267\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.332\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.331\n",
            "------Epoch 49-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.297\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.265\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.330\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.329\n",
            "------Epoch 50-------\n",
            "Mini batch: 25 | Train ACC: 0.880 | Cost: 0.295\n",
            "Mini batch: 50 | Train ACC: 1.000 | Cost: 0.263\n",
            "Mini batch: 75 | Train ACC: 0.840 | Cost: 0.329\n",
            "Mini batch: 100 | Train ACC: 0.880 | Cost: 0.328\n",
            "\n",
            "Model parameters:\n",
            "  Weights: Parameter containing:\n",
            "tensor([[ 0.8129, -1.9898],\n",
            "        [-0.8369,  0.0190],\n",
            "        [ 0.0240,  1.9708]], requires_grad=True)\n",
            "  Bias: Parameter containing:\n",
            "tensor([-0.1643,  0.2981, -0.1338], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = model2.evaluate(X_test, y_test)\n",
        "print('Test set accuracy: %.2f%%' % (test_acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnjOaUV9qBe_",
        "outputId": "6227ba42-9e57-417c-e1de-2487da01bd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy: 83.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DS0euWXLqB6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}